{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005-12\n",
      "2006-01\n"
     ]
    }
   ],
   "source": [
    "# Define the time period of interest (inclusive of ends)\n",
    "\n",
    "start_year = 2005\n",
    "start_month = 12\n",
    "\n",
    "end_year = 2006\n",
    "end_month = 1\n",
    "\n",
    "# Create a list of nicely formatted date strings\n",
    "\n",
    "from data.iterators import list_date_strings\n",
    "\n",
    "date_strings = list_date_strings(start_year=start_year,\n",
    "                                 start_month=start_month,\n",
    "                                 end_year=end_year,\n",
    "                                 end_month=end_month)\n",
    "\n",
    "from data.paths import LOCAL_COMMENTS_FMT_STR\n",
    "from data.paths import LOCAL_THREADS_FMT_STR\n",
    "from data.iterators import format_each\n",
    "from data.preprocess import records_df, td_matrix, td_matrix2\n",
    "\n",
    "comments_paths = format_each(fmt_str=LOCAL_COMMENTS_FMT_STR, *date_strings)\n",
    "threads_paths = format_each(fmt_str=LOCAL_THREADS_FMT_STR, *date_strings)\n",
    "\n",
    "print(\"\\n\".join(date_strings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download some data from pushshift.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading http://files.pushshift.io/reddit/comments/RC_2007-01.bz2\n",
      "downloading http://files.pushshift.io/reddit/submissions/RS_2007-01.bz2\n",
      "downloading http://files.pushshift.io/reddit/comments/RC_2007-02.bz2\n",
      "downloading http://files.pushshift.io/reddit/submissions/RS_2007-02.bz2\n"
     ]
    }
   ],
   "source": [
    "from data.download import download_comments_and_threads\n",
    "\n",
    "download_comments_and_threads(date_strings=date_strings,\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read comment metadata into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author\n",
      "author_flair_css_class\n",
      "author_flair_text\n",
      "body\n",
      "controversiality\n",
      "created_utc\n",
      "distinguished\n",
      "edited\n",
      "gilded\n",
      "id\n",
      "link_id\n",
      "parent_id\n",
      "retrieved_on\n",
      "score\n",
      "stickied\n",
      "subreddit\n",
      "subreddit_id\n",
      "ups\n"
     ]
    }
   ],
   "source": [
    "# Load all the wonderful comments into a dataframe and print the available columns\n",
    "comments_full_df = records_df(paths=comments_paths)\n",
    "print(\"\\n\".join(comments_full_df.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read thread metadata into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archived\n",
      "author\n",
      "author_flair_css_class\n",
      "author_flair_text\n",
      "created\n",
      "created_utc\n",
      "distinguished\n",
      "domain\n",
      "downs\n",
      "edited\n",
      "from\n",
      "from_id\n",
      "from_kind\n",
      "gilded\n",
      "hide_score\n",
      "id\n",
      "is_self\n",
      "link_flair_css_class\n",
      "link_flair_text\n",
      "media\n",
      "media_embed\n",
      "name\n",
      "num_comments\n",
      "over_18\n",
      "permalink\n",
      "quarantine\n",
      "retrieved_on\n",
      "saved\n",
      "score\n",
      "secure_media\n",
      "secure_media_embed\n",
      "selftext\n",
      "stickied\n",
      "subreddit\n",
      "subreddit_id\n",
      "thumbnail\n",
      "title\n",
      "ups\n",
      "url\n"
     ]
    }
   ],
   "source": [
    "# Load all the wonderful threads into a dataframe and print the available columns\n",
    "threads_full_df = records_df(paths=threads_paths)\n",
    "print(\"\\n\".join(threads_full_df.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read a subset of comment metadata into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      author   subreddit\n",
      "0       frjo  reddit.com\n",
      "1    zse7zse  reddit.com\n",
      "2  [deleted]  reddit.com\n",
      "3  [deleted]  reddit.com\n",
      "4    rjoseph  reddit.com\n"
     ]
    }
   ],
   "source": [
    "# pass any subset of column names as a list to the records_df function\n",
    "# and it will construct a dataframe with only those columns.\n",
    "# This will usually be faster than constructing the full dataframe.\n",
    "comments_partial_df = records_df(paths=comments_paths, keys=[\"author\", \"subreddit\"])\n",
    "print(comments_partial_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a lists of unique users and subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.5 ms ± 811 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "author_subreddit_df = records_df(paths=comments_paths, keys=[\"author\", \"subreddit\"])\n",
    "\n",
    "# # Each entry in the resulting series is the number of comments associated with a particular user\n",
    "# author_comment_counts = author_subreddit_df[\"author\"].value_counts()\n",
    "\n",
    "# # Each entry in the resulting series is the number of comments on the associated subreddit\n",
    "# subreddit_comment_counts = author_subreddit_df[\"subreddit\"].value_counts()\n",
    "# print(author_comment_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get dicts of unique users and subreddits more efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.7 ms ± 507 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "td_mat1 = td_matrix(paths=comments_paths, term_key=\"author\", doc_key=\"subreddit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.4 ms ± 823 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "td_mat2 = td_matrix2(paths=comments_paths, term_key=\"author\", doc_key=\"subreddit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
